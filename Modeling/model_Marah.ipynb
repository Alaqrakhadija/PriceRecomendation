{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8005d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV\n",
    "from scipy.stats import uniform\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from wordcloud import  STOPWORDS\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c295fb81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef1777a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOADING THE  TRAIN DATASET\n",
    "df =  pd.read_csv(r\"C:\\Users\\Msys\\Desktop\\Data Science-GSG\\train.tsv\",index_col=[\"train_id\"],sep='\\t')\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed3b0a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOADING THE TEST DATASET\n",
    "df_test  =pd.read_csv(r\"C:\\Users\\Msys\\Desktop\\Data Science-GSG\\test.tsv\",index_col=[\"test_id\"],sep='\\t')\n",
    "#df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703dd420",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9668b76b",
   "metadata": {},
   "source": [
    "## Basic Statictics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b54a542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1482535, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GETTING THE SHAPE OF THE DATASET\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7d1cfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1482535 entries, 0 to 1482534\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count    Dtype  \n",
      "---  ------             --------------    -----  \n",
      " 0   name               1482535 non-null  object \n",
      " 1   item_condition_id  1482535 non-null  int64  \n",
      " 2   category_name      1476208 non-null  object \n",
      " 3   brand_name         849853 non-null   object \n",
      " 4   price              1482535 non-null  float64\n",
      " 5   shipping           1482535 non-null  int64  \n",
      " 6   item_description   1482531 non-null  object \n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 90.5+ MB\n"
     ]
    }
   ],
   "source": [
    "#GETTING THE BASIC INFO ABOUT THE DATASET\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0eb8a4",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51b82fb",
   "metadata": {},
   "source": [
    "### 'price'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93304032",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS CELL CREATES NEW COLOMN WITH LOG(PRICE+1)\n",
    "df[\"log_price\"] = df.price.apply(lambda x:np.log(x+1))\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfaaaf7b",
   "metadata": {},
   "source": [
    "### 'name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d10f52af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS CELL PREPROCESSES THE NAME FEATURE\n",
    "\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase\n",
    "\n",
    "st_words = stopwords.words('english')\n",
    "\n",
    "def name_process(text):\n",
    "    '''THIS FUNCTION IS USED TO PREPROCESS THE NAME FEATURE'''\n",
    "    text = decontracted(text)\n",
    "    text = re.sub(\"[^A-Za-z0-9 ]\",\"\",text) # REMOVE EVERYTHING EXCEPT THE PROVIDED CHARACTERS\n",
    "    text = text.lower() # CONVERT TO LOWER CASE\n",
    "    text =  \" \".join([i for i in text.split() if i not in st_words])\n",
    "    if len(text)==0:\n",
    "        text = \"missing\"\n",
    "    return text # RETURN THE OUTPUT TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5eaeb221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPLYING THE \"preprocessing\" FUNCTION ON THE FEAUTRE \"name\"\n",
    "df[\"name_processed\"] = df.name.apply(name_process)\n",
    "df[df.name_processed.isnull()].name_processed =\"missing\" \n",
    "\n",
    "# APPLYING THE \"preprocessing\" FUNCTION ON THE FEAUTRE \"name\" on test data\n",
    "df_test[\"name_processed\"] = df_test.name.apply(name_process)\n",
    "df_test[df_test.name_processed.isnull()].name_processed =\"missing\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6c66f5",
   "metadata": {},
   "source": [
    "### brand_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bde22fb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''CREATING PREPROCESSING FUNCTION FOR BRAND NAME'''\n",
    "def brand_process(text):\n",
    "    text = re.sub(\"[^A-Za-z0-9 ]\",\"\",text)# REMOVE EVERYTHING EXCEPT THE PROVIDED CHARACTERS\n",
    "    text = text.lower()  # CONVERT TO LOWER CASE\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1fadb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1482535it [02:27, 10075.94it/s]\n"
     ]
    }
   ],
   "source": [
    "# here we are assigning score correrponding to each brand_name\n",
    "# the easiest way is to assign the score equals to number of occurences for that brand and store in the form of dict.\n",
    "brand_score = dict(df[df.brand_name.notnull()][\"brand_name\"].apply(brand_process).value_counts())\n",
    "\n",
    "processed_brand_name = [] #storing the barand name after preprocessing\n",
    "for index,i in tqdm(df.iterrows()) : # for each row in the dataset\n",
    "    \n",
    "    if  pd.isnull(i.brand_name): #if the brand name isnull we follow this\n",
    "        \n",
    "        words = i.name_processed.split() # we will split the name for that datapoint\n",
    "        score  = [] # this variable stores the score for each word that we calculated above\n",
    "        for j in words: # for each word \n",
    "            if j in brand_score.keys(): #if the words in name is present in the keys of brand score dict\n",
    "                score.append(brand_score[j]) # take the score from the dict and append in the score variable\n",
    "            else: #if the word is not a brand name append -1\n",
    "                score.append(-1)\n",
    "        # once we get the scores for all the words in the name the word with maximum score woulb be the brand name\n",
    "        if max(score) > 0: #if the maximum score is greater than 0 then it contains a brand name so we append the brand name\n",
    "            processed_brand_name.append(words[score.index(max(score))])\n",
    "        else: # if maximum value is less than 0 then it means no brand name was found so \"missing\" is appended\n",
    "            processed_brand_name.append(\"missing\")\n",
    "            \n",
    "    else: # if the brand_name is not null we follow this\n",
    "        processed_brand_name.append(brand_process(i.brand_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ee66787",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATING NEW COLUMN WITH PROCESSED BRAND NAMES\n",
    "df[\"brand_name_processed\"] = processed_brand_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26ba1cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "693359it [01:08, 10056.83it/s]\n"
     ]
    }
   ],
   "source": [
    "#APPLYING PROCESSING TO TEST DATASET BRAND NAME\n",
    "processed_brand_name_test = []\n",
    "for index,i in tqdm(df_test.iterrows()) :\n",
    "    \n",
    "    if  pd.isnull(i.brand_name):\n",
    "        \n",
    "        words = i.name_processed.split()\n",
    "        score  = []\n",
    "        for j in words:\n",
    "            if j in brand_score.keys():\n",
    "                score.append(brand_score[j])\n",
    "            else:\n",
    "                score.append(-1)\n",
    "        \n",
    "        if max(score) > 0:\n",
    "            processed_brand_name_test.append(words[score.index(max(score))])\n",
    "        else:\n",
    "            processed_brand_name_test.append(\"missing\")\n",
    "    else:\n",
    "        processed_brand_name_test.append(brand_process(i.brand_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ed2251f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATING NEW COLUMN WITH PROCESSED BRAND NAMES\n",
    "df_test[\"brand_name_processed\"] = processed_brand_name_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f4fc30",
   "metadata": {},
   "source": [
    "### category_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54983380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPROCESS THE  \"category_name\" \n",
    "\n",
    "def category_name_preprocessing(text):\n",
    "    #THIS FUNCTION PREPROCESSES THE TEXT IN \"category_name\" FEATURE\n",
    "    text = re.sub(\"[^A-Za-z0-9/ ]\",\"\",text)# REMOVING ALL THE TEXT EXCEPT THE GIVEN CHARACTERS\n",
    "    text = re.sub(\"s \",\" \",text) # REMOVING  \"s\" AT THE END OF THE WORD\n",
    "    text = re.sub(\"s/\",\"/\",text) # REMOVING  \"s\" AT THE END OF THE WORD\n",
    "    text = re.sub(\"  \",\" \",text) # REMOVING ONE SPACE WHERE TWO SPACES ARE PRESENT\n",
    "    text = text.lower() # CONVERTING THE TEXT TO LOWER CASE\n",
    "    return text # RETURNING THE PROCESSED TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e2f8602",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS CELL REPLACE THE NULL VALUES WITH WORD \"missing\" AND PREPROCESSES THE category_name FEATURE\n",
    "\n",
    "# HERE WE ARE REPLACING THE NULL VALUES IN \"category_name\" WITH WORD \"missing\"\n",
    "df.category_name[df.category_name.isnull()] = \"missing\"\n",
    "# HERE WE ARE PREPROCESSING THE TEXT IN \"category_name\"\n",
    "df[\"category_name_preprocessed\"] = df.category_name.apply(category_name_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91d169c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPROCESSING ON TEST DATA\n",
    "df_test.category_name[df_test.category_name.isnull()] = \"missing\"\n",
    "df_test[\"category_name_preprocessed\"] = df_test.category_name.apply(category_name_preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdbbe17",
   "metadata": {},
   "source": [
    "## Division of category_name\n",
    "### 'Tier_1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ccff5ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS CELL SPLITS THE TOTAL CATEGORY NAME WITH \"/\" AND WHERE NULL IS PRESENT \"missing\" IS USED\n",
    "\n",
    "# FORMING A COLUMN \"Tier_1\"\n",
    "df[\"Tier_1\"] = df.category_name_preprocessed.apply(lambda x:   x.split(\"/\")[0] if len(x.split(\"/\"))>=1 else \"missing\")\n",
    "\n",
    "# PREPROCESSING ON TEST DATA\n",
    "df_test[\"Tier_1\"] = df_test.category_name_preprocessed.apply(lambda x:   x.split(\"/\")[0] if len(x.split(\"/\"))>=1 else \"missing\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8570dbb",
   "metadata": {},
   "source": [
    "### 'Tier_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5762e47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FORMING A COLUMN \"Tier_2\"\n",
    "df[\"Tier_2\"] = df.category_name_preprocessed.apply(lambda x:   x.split(\"/\")[1] if len(x.split(\"/\"))>1 else \"missing\")\n",
    "# PREPROCESSING ON TEST DATA\n",
    "df_test[\"Tier_2\"] = df_test.category_name_preprocessed.apply(lambda x:   x.split(\"/\")[1] if len(x.split(\"/\"))>1 else \"missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd1e5ee",
   "metadata": {},
   "source": [
    "### 'Tier_3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed8ccc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FORMING A COLUMN \"Tier_3\"\n",
    "df[\"Tier_3\"] = df.category_name_preprocessed.apply(lambda x:   x.split(\"/\")[2] if len(x.split(\"/\"))>1 else \"missing\")\n",
    "# PREPROCESSING ON TEST DATA\n",
    "df_test[\"Tier_3\"] = df_test.category_name_preprocessed.apply(lambda x:   x.split(\"/\")[2] if len(x.split(\"/\"))>1 else \"missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738faa71",
   "metadata": {},
   "source": [
    "## 'item_description'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8551bc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREPROCESSING FUNCTION FOR ITEM DESCRIPTION\n",
    "def processing_item_description(text):\n",
    "    '''THIS FUNCTION PREPROCESSES THE TEXT IN \"item_description\"'''\n",
    "    text = re.sub(\"\\[rm\\] \",\"\",str(text))\n",
    "    text = decontracted(text)\n",
    "    text = re.sub(\"[^A-Za-z0-9 ]\",\"\",str(text))\n",
    "    text = str(text).lower()\n",
    "    text =  \" \".join([i for i in text.split() if i not in st_words])\n",
    "    if len(text)==0:\n",
    "        text = \"missing\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91fe68e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#REPLACING THE NULL VALUVE WITH WORD \"missing\"\n",
    "df.item_description[df.item_description.isnull()]=\"missing\"\n",
    "\n",
    "#HERE WE ARE PREPROCESSING THE TEXT IN FEATURE \"item_description\" '''\n",
    "df[\"processed_item_description\"] = df.item_description.apply(processing_item_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e792a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPROCESSING FOR TEST DATA\n",
    "df_test.item_description[df_test.item_description.isnull()]=\"missing\"\n",
    "df_test[\"processed_item_description\"] = df_test.item_description.apply(processing_item_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0654fbd",
   "metadata": {},
   "source": [
    "### PREPROCESSING FOR WORD CLOUD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "175b5755",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1482535it [03:25, 7223.69it/s]\n"
     ]
    }
   ],
   "source": [
    "#THIS CELL JOINS ALL THE NAMES OF SPECIFIC ITEM CONDITON TOGETHER\n",
    "# PLACEHOLDERS\n",
    "id_1=\"\"\n",
    "id_2=\"\"\n",
    "id_3=\"\"\n",
    "id_4=\"\"\n",
    "id_5=\"\"\n",
    "# FOR EACH ROW IN DATASET\n",
    "for index ,i in tqdm(df[[\"name_processed\",\"item_condition_id\"]].iterrows()):\n",
    "    # JOIN THE STRIG TO SPECIFIC ITEM CONDITION ID\n",
    "    if i.item_condition_id==1:\n",
    "        id_1+= i.name_processed\n",
    "    if i.item_condition_id==2:\n",
    "        id_2+= i.name_processed\n",
    "    if i.item_condition_id==3:\n",
    "        id_3+= i.name_processed\n",
    "    if i.item_condition_id==4:\n",
    "        id_4+= i.name_processed\n",
    "    if i.item_condition_id==5:\n",
    "        id_5+= i.name_processed\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63042b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STORING THE STOPWORDS IN A VARIABLE\n",
    "stopword = stopwords.words('english')\n",
    "\n",
    "#FORMING WORDCLOUDS\n",
    "wordcloud1 = WordCloud(width = 800, height = 800,\n",
    "                background_color ='black',\n",
    "                stopwords = stopword,\n",
    "                min_font_size = 10).generate(id_1)\n",
    "wordcloud2 = WordCloud(width = 800, height = 800,\n",
    "                background_color ='black',\n",
    "                stopwords = stopword,\n",
    "                min_font_size = 10).generate(id_2)\n",
    "wordcloud3 = WordCloud(width = 800, height = 800,\n",
    "                background_color ='black',\n",
    "                stopwords = stopword,\n",
    "                min_font_size = 10).generate(id_3)\n",
    "wordcloud4 = WordCloud(width = 800, height = 800,\n",
    "                background_color ='black',\n",
    "                stopwords = stopword,\n",
    "                min_font_size = 10).generate(id_4)\n",
    "wordcloud5 = WordCloud(width = 800, height = 800,\n",
    "                background_color ='black',\n",
    "                stopwords = stopword,\n",
    "                min_font_size = 10).generate(id_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ec533f",
   "metadata": {},
   "source": [
    "### 10. item_description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0969680a",
   "metadata": {},
   "source": [
    "### World cloud Analysis For Item Description "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "daa147c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1482535it [13:27, 1836.02it/s]\n"
     ]
    }
   ],
   "source": [
    "#JOINS ALL THE ITEM DESCRIPTION OF SPECIFIC ITEM CONDITON TOGETHER\n",
    "\n",
    "# PLACEHOLDER \n",
    "id_1_desc=\"\"\n",
    "id_2_desc=\"\"\n",
    "id_3_desc=\"\"\n",
    "id_4_desc=\"\"\n",
    "id_5_desc=\"\"\n",
    "# FOR EACH POINTS IN THE DATASET\n",
    "for index ,i in tqdm(df[[\"processed_item_description\",\"item_condition_id\"]].iterrows()):\n",
    "    # JOINGING THE SRTING BASED ON ITEM CONDITON ID\n",
    "    if i.item_condition_id==1:\n",
    "        id_1_desc += i.processed_item_description\n",
    "    if i.item_condition_id==2:\n",
    "        id_2_desc  += i.processed_item_description\n",
    "    if i.item_condition_id==3:\n",
    "        id_3_desc  += i.processed_item_description\n",
    "    if i.item_condition_id==4:\n",
    "        id_4_desc  += i.processed_item_description\n",
    "    if i.item_condition_id==5:\n",
    "        id_5_desc  += i.processed_item_description\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b88ca898",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FORMING THE WORD CLOUDS\n",
    "\n",
    "wordcloud1_desc = WordCloud(width = 800, height = 800,\n",
    "                background_color ='black',\n",
    "                stopwords = stopword,\n",
    "                min_font_size = 10).generate(id_1_desc)\n",
    "wordcloud2_desc = WordCloud(width = 800, height = 800,\n",
    "                background_color ='black',\n",
    "                stopwords = stopword,\n",
    "                min_font_size = 10).generate(id_2_desc)\n",
    "wordcloud3_desc = WordCloud(width = 800, height = 800,\n",
    "                background_color ='black',\n",
    "                stopwords = stopword,\n",
    "                min_font_size = 10).generate(id_3_desc)\n",
    "wordcloud4_desc = WordCloud(width = 800, height = 800,\n",
    "                background_color ='black',\n",
    "                stopwords = stopword,\n",
    "                min_font_size = 10).generate(id_4_desc)\n",
    "wordcloud5_desc = WordCloud(width = 800, height = 800,\n",
    "                background_color ='black',\n",
    "                stopwords = stopword,\n",
    "                min_font_size = 10).generate(id_5_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8cf2836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STORING THE CSV FILE \n",
    "df.to_csv(\"train_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0faa5b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STORING THE CSV FILE \n",
    "df_test.to_csv(\"test_processed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55cd12a",
   "metadata": {},
   "source": [
    "# Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4db5b01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train,df_val = train_test_split(df,test_size=0.1,random_state = 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e617c9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of df_train :  (1334281, 15)\n",
      "size of df_val : (148254, 15)\n",
      "size of df_test : (693359, 13)\n"
     ]
    }
   ],
   "source": [
    "print(\"size of df_train : \",df_train.shape)\n",
    "print(\"size of df_val :\",df_val.shape)\n",
    "print(\"size of df_test :\",df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3447cfa6",
   "metadata": {},
   "source": [
    "### Value of Target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c7267e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train.log_price\n",
    "y_val = df_val.log_price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a4d048",
   "metadata": {},
   "source": [
    "### 1.  item_condition_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6ab0d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1334281, 5)\n",
      "(148254, 5)\n",
      "(693359, 5)\n"
     ]
    }
   ],
   "source": [
    "#ITEM CONDITION ID ONE HOT ENDODING\n",
    "train_vec_item_con = pd.get_dummies(df_train.item_condition_id).values\n",
    "val_vec_item_con = pd.get_dummies(df_val.item_condition_id).values\n",
    "test_vec_item_con = pd.get_dummies(df_test.item_condition_id).values\n",
    "\n",
    "print(train_vec_item_con.shape)\n",
    "print(val_vec_item_con.shape)\n",
    "print(test_vec_item_con.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8214feb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['item_enc.pkl']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(train_vec_item_con, 'item_enc.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ae80034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78f6858",
   "metadata": {},
   "source": [
    "### 2.  shipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c50f6a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1334281, 2)\n",
      "(148254, 2)\n",
      "(693359, 2)\n"
     ]
    }
   ],
   "source": [
    "#SHIPPING ONE HOT ENCODING\n",
    "train_vec_shipping = pd.get_dummies(df_train.shipping).values\n",
    "val_vec_shipping = pd.get_dummies(df_val.shipping).values\n",
    "test_vec_shipping = pd.get_dummies(df_test.shipping).values\n",
    "\n",
    "\n",
    "print(train_vec_shipping.shape)\n",
    "print(val_vec_shipping.shape)\n",
    "print(test_vec_shipping.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "89e459cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['shipping_enc.pkl']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(train_vec_shipping, 'shipping_enc.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d4624e",
   "metadata": {},
   "source": [
    "### 3.  brand_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2fd2da1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1334281, 4702)\n",
      "(148254, 4702)\n",
      "(693359, 4702)\n"
     ]
    }
   ],
   "source": [
    "#BRAND NAME ONE HOT ENCODING\n",
    "label_brand = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "label_brand.fit(df_train.brand_name_processed.values.reshape(-1,1))\n",
    "\n",
    "train_vec_brand =label_brand.transform(df_train.brand_name_processed.values.reshape(-1,1))\n",
    "val_vec_brand = label_brand.transform(df_val.brand_name_processed.values.reshape(-1,1))\n",
    "test_vec_brand = label_brand.transform(df_test.brand_name_processed.values.reshape(-1,1))\n",
    "\n",
    "print(train_vec_brand.shape)\n",
    "print(val_vec_brand.shape)\n",
    "print(test_vec_brand.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "27415d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['brand_enc.pkl']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(label_brand, 'brand_enc.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11373eb3",
   "metadata": {},
   "source": [
    "### 4.  Tier_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "12ac3c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1334281, 11)\n",
      "(148254, 11)\n",
      "(693359, 11)\n"
     ]
    }
   ],
   "source": [
    "#TIER1 ONE HOT ENCODING\n",
    "label_t1 = OneHotEncoder(handle_unknown='ignore')\n",
    "label_t1.fit(df_train.Tier_1.values.reshape(-1,1))\n",
    "\n",
    "train_vec_t1 = label_t1.transform(df_train.Tier_1.values.reshape(-1,1))\n",
    "val_vec_t1 =   label_t1.transform(df_val.Tier_1.values.reshape(-1,1))\n",
    "test_vec_t1 =   label_t1.transform(df_test.Tier_1.values.reshape(-1,1))\n",
    "\n",
    "\n",
    "print(train_vec_t1.shape)\n",
    "print(val_vec_t1.shape)\n",
    "print(test_vec_t1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c2a9e91c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tier_enc.pkl']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(label_t1, 'tier_enc.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24116bf",
   "metadata": {},
   "source": [
    "### 5.  Tier_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a977d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1334281, 111)\n",
      "(148254, 111)\n",
      "(693359, 111)\n"
     ]
    }
   ],
   "source": [
    "'''TIER2 ONE HOT ENCODING'''\n",
    "\n",
    "label_t2 = OneHotEncoder(handle_unknown='ignore')\n",
    "label_t2.fit(df_train.Tier_2.values.reshape(-1,1))\n",
    "\n",
    "train_vec_t2 =label_t2.transform(df_train.Tier_2.values.reshape(-1,1))\n",
    "val_vec_t2 = label_t2.transform(df_val.Tier_2.values.reshape(-1,1))\n",
    "test_vec_t2 = label_t2.transform(df_test.Tier_2.values.reshape(-1,1))\n",
    "\n",
    "print(train_vec_t2.shape)\n",
    "print(val_vec_t2.shape)\n",
    "print(test_vec_t2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5ca40bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tier2_enc.pkl']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(label_t2, 'tier2_enc.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4e5b44",
   "metadata": {},
   "source": [
    "### 6. Tier_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3fbf2e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1334281, 863)\n",
      "(1334281, 863)\n",
      "(693359, 863)\n"
     ]
    }
   ],
   "source": [
    "#TIER 3 ONE HOT ENDODING\n",
    "\n",
    "label_t3 = OneHotEncoder(handle_unknown='ignore')\n",
    "label_t3.fit(df_train.Tier_3.values.reshape(-1,1))\n",
    "\n",
    "train_vec_t3 =label_t3.transform(df_train.Tier_3.values.reshape(-1,1))\n",
    "val_vec_t3 = label_t3.transform(df_val.Tier_3.values.reshape(-1,1))\n",
    "test_vec_t3 = label_t3.transform(df_test.Tier_3.values.reshape(-1,1))\n",
    "\n",
    "print(train_vec_t3.shape)\n",
    "print(train_vec_t3.shape)\n",
    "print(test_vec_t3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0e354a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tier3_enc.pkl']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(label_t3, 'tier3_enc.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aee4075",
   "metadata": {},
   "source": [
    "## Text Data - Tfidf\n",
    "### 7. name_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6473f47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1334281, 50000)\n",
      "(148254, 50000)\n",
      "(693359, 50000)\n"
     ]
    }
   ],
   "source": [
    "#PROCESSED NAME TFIDF VECTORIZER\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2),max_features=50000)\n",
    "tfidf.fit(df_train.name_processed)\n",
    "\n",
    "train_vec_name = tfidf.transform(df_train.name_processed)\n",
    "val_vec_name = tfidf.transform(df_val.name_processed)\n",
    "test_vec_name = tfidf.transform(df_test.name_processed) \n",
    "\n",
    "\n",
    "print(train_vec_name.shape)\n",
    "print(val_vec_name.shape)\n",
    "print(test_vec_name.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a747f4c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name_tfidf_enc.pkl']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(tfidf, 'name_tfidf_enc.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f850e0",
   "metadata": {},
   "source": [
    "### 8. processed_item_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0d00245a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1334281, 50000)\n",
      "(148254, 50000)\n",
      "(693359, 50000)\n"
     ]
    }
   ],
   "source": [
    "'''PROCESSED ITEM DESCRIPTION TFIDF VECTORIZATION'''\n",
    "\n",
    "tfidf_desc = TfidfVectorizer(max_features=50000,ngram_range=(1, 2))\n",
    "tfidf_desc.fit(df_train.processed_item_description)\n",
    "\n",
    "train_vec_desc = tfidf_desc.transform(df_train.processed_item_description)\n",
    "val_vec_desc   = tfidf_desc.transform(df_val.processed_item_description)\n",
    "test_vec_desc   = tfidf_desc.transform(df_test.processed_item_description) \n",
    "\n",
    "print(train_vec_desc.shape)\n",
    "print(val_vec_desc.shape)\n",
    "print(test_vec_desc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b52d7ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['desc_tfidf_enc.pkl']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(tfidf_desc, 'desc_tfidf_enc.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d5b2f2",
   "metadata": {},
   "source": [
    "### 9. is_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0e4e32af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IS MISSIN FEATURE FOR TRAIN DATASET\n",
    "\n",
    "df_train[\"is_missing\"]  =  (df_train.brand_name_processed==\"missing\") | (df_train.name_processed ==\"missing\")| (df_train.processed_item_description==\"missing\")\n",
    "df_train[\"is_missing\"]  = df_train[\"is_missing\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f1792511",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IS MISSING FEATURE FOR VALIDATION DATASET\n",
    "\n",
    "df_val[\"is_missing\"]  =  (df_val.brand_name_processed==\"missing\") | (df_val.name_processed ==\"missing\")| (df_val.processed_item_description==\"missing\")\n",
    "df_val[\"is_missing\"]  = df_val[\"is_missing\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "63d2e236",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IS MISSING FEATURE FOR TEST DATASET\n",
    "\n",
    "df_test[\"is_missing\"]  =  (df_test.brand_name_processed==\"missing\") | (df_test.name_processed ==\"missing\")| (df_test.processed_item_description==\"missing\")\n",
    "df_test[\"is_missing\"]  = df_test[\"is_missing\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc4d6b2",
   "metadata": {},
   "source": [
    "## Concatenating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cee9819e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1334281, 105695)\n",
      "(148254, 105695)\n",
      "(693359, 105695)\n"
     ]
    }
   ],
   "source": [
    "#STACKING ALL THE FEATURES\n",
    "\n",
    "\n",
    "# STACKING TRAIN FEATURES\n",
    "x_train = hstack((train_vec_item_con,train_vec_shipping,\n",
    "                  train_vec_name,train_vec_brand,train_vec_t1,\n",
    "                   train_vec_t2,\n",
    "                    train_vec_t3,\n",
    "                  df_train.is_missing.values.reshape(-1,1)\n",
    "                   ,train_vec_desc))\n",
    "\n",
    "\n",
    "# STACKING VALIDATION FEATURES\n",
    "x_val = hstack((val_vec_item_con,val_vec_shipping\n",
    "                ,val_vec_name ,val_vec_brand ,val_vec_t1 ,\\\n",
    "                  val_vec_t2 ,val_vec_t3 ,\n",
    "                df_val.is_missing.values.reshape(-1,1)\n",
    "                ,val_vec_desc))\n",
    "\n",
    "# STACKING TEST FEATURES\n",
    "x_test = hstack((test_vec_item_con,test_vec_shipping\n",
    "                ,test_vec_name ,test_vec_brand ,test_vec_t1 ,\\\n",
    "                  test_vec_t2 ,test_vec_t3 ,\n",
    "                df_test.is_missing.values.reshape(-1,1)\n",
    "                ,test_vec_desc))\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca3651e",
   "metadata": {},
   "source": [
    "## C. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085a7659",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "479765e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=10)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_best = Ridge(alpha=10)\n",
    "l2_best.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "60795c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN PREDICTION\n",
    "train_pred = l2_best.predict(x_train)\n",
    "# VALIDATION PREDICTION\n",
    "val_pred = l2_best.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c65b384d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error =  0.4414232731512226\n",
      "Validation Error =  0.458116634015336\n"
     ]
    }
   ],
   "source": [
    "# TRAIN ERROR\n",
    "train_error = np.sqrt(mean_squared_error(y_train,train_pred))\n",
    "print(\"Train Error = \",train_error)\n",
    "# VALIDATION ERROR\n",
    "val_error = np.sqrt(mean_squared_error(y_val,val_pred))\n",
    "print(\"Validation Error = \",val_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b70023",
   "metadata": {},
   "source": [
    "## Save and Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "040f0ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b56b6d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"model.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "767195ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "pickle.dump(l2_best, open(filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b4b11d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "loaded_model = pickle.load(open(filename, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c6baf23f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.33799407, 2.80459348, 3.42413218, ..., 2.63513667, 2.98044463,\n",
       "       2.40071126])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "89cb6222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.pkl']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(l2_best, 'model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7fe96c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d27d74fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = {\n",
    "                'name': \"AVA-VIV Blouse\",\n",
    "                'item_condition_id': 1,\n",
    "                'category_name': \"Women/Tops & Blouses/Blouse\t\",\n",
    "                'brand_name': \"Target\",\n",
    "                'shipping': 1,\n",
    "                'item_description': \"Adorable top with a hint of lace and a key hole in the back! The pale pink is a 1X, and I also have a 3X available in white!\"\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "15bae785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.22584058, 3.27447237, 3.53139173, ..., 2.64531353, 2.90090842,\n",
       "       4.89792012])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_best.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e8c43f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693553dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
